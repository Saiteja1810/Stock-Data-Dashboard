#  Stock Data Dashboard (Streamlit + Pandas + PyArrow)

A minimal project demonstrating data cleaning, aggregation, and visualization of stock market data using Python and Streamlit.

##  Objective
This project processes raw stock market data to:
1. Normalize and clean inconsistent values and formats.
2. Define and enforce a target schema (dates, strings, floats, bools).
3. Generate Parquet outputs for cleaned and aggregated data.
4. Visualize metrics interactively in Streamlit.

## ðŸš€ Key Features
- Data cleaning and preprocessing
- Aggregated datasets:
  â€¢ Daily average close per ticker
  â€¢ Average volume per sector
  â€¢ Daily returns per ticker
- Streamlit dashboard for data exploration
- Parquet outputs for efficient loading

##  Project Structure
stocks/
â”œâ”€â”€ raw_data.csv
â”œâ”€â”€ load_data.py
â”œâ”€â”€ clean_data.py
â”œâ”€â”€ aggregate_data.py
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ cleaned.parquet
â”œâ”€â”€ agg1.parquet
â”œâ”€â”€ agg2.parquet
â”œâ”€â”€ agg3.parquet
â”œâ”€â”€ screenshot.zip
â””â”€â”€ README.md

##  Data Description
raw_data.csv contains columns:
date, ticker, open, high, low, close, volume, sector

Outputs:
cleaned.parquet â€“ cleaned dataset
agg1.parquet â€“ daily avg close per ticker
agg2.parquet â€“ avg volume by sector
agg3.parquet â€“ daily returns

##  Pipeline Steps
1) Load Raw Data:
   python load_data.py

2) Clean Data:
   python clean_data.py

3) Create Aggregates:
   python aggregate_data.py

##  Run Dashboard
streamlit run streamlit_app.py

##  Screenshots
Screenshots available in screenshot.zip

##  How to Use
1. Add raw_data.csv
2. Run all three scripts
3. Launch Streamlit dashboard
4. Explore visualizations

## License
Open for personal and educational use.
